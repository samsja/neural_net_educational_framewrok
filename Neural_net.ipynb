{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.genfromtxt('data/training_set.csv', delimiter=',')\n",
    "validation_data = np.genfromtxt('data/validation_set.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    return data[:,0:2],np.expand_dims(data[:,-1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000, 1))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_inputs,training_outputs = preprocess_data(training_data)\n",
    "(training_inputs.shape,training_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs,validation_outputs = preprocess_data(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. define a layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer_Perceptron:\n",
    "    \n",
    "    def __init__(self,number_of_input,number_of_neurons,activation_function,derivate_activation_function,weight=None,bias=None,random_weight=True,weight_range=0.2,bias_range=1):\n",
    "        \n",
    "        self.n = number_of_input\n",
    "        self.m = number_of_neurons\n",
    "        self._activation_function = activation_function\n",
    "        self._derivate_activation_function = derivate_activation_function\n",
    "        \n",
    "        if (weight==None):\n",
    "            if random_weight:\n",
    "                self.w = weight_range*(2*np.random.rand(self.n,self.m)-1)\n",
    "            else:\n",
    "                self.w = np.zeros((self.n,self.m))\n",
    "        \n",
    "        else:\n",
    "            if not(weight.shape== (self.n,)):\n",
    "                raise ValueError(f\"weight param should be of shape ({self.n},) but it is {weight.shape}\")\n",
    "            else:\n",
    "                self.w = weight\n",
    "        \n",
    "        if (bias==None):\n",
    "            if random_weight:\n",
    "                self.b= bias_range*(2*np.random.rand(self.m,1)-1)\n",
    "            else:\n",
    "                self.b = 0\n",
    "        \n",
    "        else:\n",
    "            self.b = bias\n",
    "    \n",
    "    \n",
    "    def local_field(self,x):\n",
    "        return ((self.w.T@x.T) + self.b).T\n",
    "    \n",
    "    def activate(self,x):        \n",
    "        return self._activate_lf(self.local_field(x))\n",
    "    \n",
    "    def _activate_lf(self,lf):\n",
    "        return self._activation_function(lf)\n",
    "    \n",
    "    def grad(self,x):\n",
    "        return self._grad_lf(self.local_field(x))\n",
    "\n",
    "    def _grad_lf(self,lf):\n",
    "        return self._derivate_activation_function(lf)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = lambda x : np.tanh(x)\n",
    "derivate_activation_func = lambda x :  (1-np.tanh(x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = 3\n",
    "M2 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer_Perceptron(training_inputs.shape[1],M1,activation_func,derivate_activation_func)\n",
    "layer2 = Layer_Perceptron(layer1.w.shape[1],M2,activation_func,derivate_activation_func)\n",
    "layer3 = Layer_Perceptron(layer2.w.shape[1],1,activation_func,derivate_activation_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.activate(training_inputs[0:1,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.activate(training_inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.grad(training_inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3.activate(layer2.activate(layer1.activate(training_inputs))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Energies functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction:\n",
    "    \n",
    "    def __init__(self,loss,grad):\n",
    "        self.loss = loss\n",
    "        self.grad = grad\n",
    "    \n",
    "    def total_loss(self,inputs,outputs):\n",
    "        return self.loss(inputs,outputs).mean()\n",
    "    \n",
    "    def total_grad(self,inputs,outputs):\n",
    "        return self.grad(inputs,outputs).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_func(inputs,real_values):\n",
    "    return ((inputs-real_values)**2)\n",
    "\n",
    "def energy_derivate(inputs,real_values):\n",
    "    return 2*(inputs-real_values)\n",
    "\n",
    "energy = LossFunction(energy_func,energy_derivate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        \n",
    "        self.L = len(layers)\n",
    "        self.layers = layers\n",
    "    \n",
    "    def activate(self,inputs,l=None): \n",
    "        if l == None:\n",
    "            l= self.L-1\n",
    "        if l ==-1:\n",
    "            return inputs\n",
    "        return self.layers[l]._activate_lf(self.local_field_forwad(inputs,l))\n",
    "        \n",
    "        \n",
    "    def local_field_forwad(self,inputs,l):\n",
    "        outputs = inputs\n",
    "        for i in range(l):\n",
    "            outputs = self.layers[i].activate(outputs)\n",
    "        \n",
    " \n",
    "        local_field = self.layers[l].local_field(outputs)\n",
    "            \n",
    "        return local_field  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNet([layer1,layer2,layer3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.local_field_forwad(training_inputs,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.activate(training_inputs,2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = energy\n",
    "inputs = training_inputs[0:10]\n",
    "outputs = training_outputs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad(nn.activate(inputs),outputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3.w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(10, 1)\n",
      "(10, 4)\n",
      "(10, 1)\n",
      "(10, 4)\n",
      "\n",
      "1\n",
      "(10, 4)\n",
      "(10, 3)\n",
      "(10, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,3) (10,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-714-ac865b6dd2eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgrad_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,3) (10,4) "
     ]
    }
   ],
   "source": [
    "grads_w = [np.zeros(layer.w.shape) for layer in nn.layers]\n",
    "grads_b = [np.zeros(layer.b.shape) for layer in nn.layers]\n",
    "\n",
    "\n",
    "back_prop = loss.grad(nn.activate(inputs),outputs)\n",
    "for i in reversed(range(nn.L)):\n",
    "    l = nn.layers[i]\n",
    "      \n",
    "    grad_layer = l._grad_lf(nn.local_field_forwad(inputs,i))\n",
    "    activation= nn.activate(inputs,i-1)\n",
    "    \n",
    "    print(i)\n",
    "    print(grad_layer.shape)\n",
    "    print(activation.shape)\n",
    "    print(back_prop.shape)\n",
    "\n",
    "    \n",
    "    grad_w = activation*(back_prop*grad_layer)\n",
    "    grad_b = np.ones(activation.shape)*(back_prop*grad_layer)\n",
    "    \n",
    "    print(grad_w.shape)\n",
    "    back_prop = (grad_layer*back_prop)@l.w.T\n",
    "    \n",
    "\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.local_field_forwad(inputs,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.local_field_forwad(inputs,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'la' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-408-17484aedd05f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'la' is not defined"
     ]
    }
   ],
   "source": [
    "layer1.activate(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54472783],\n",
       "       [0.54755609],\n",
       "       [0.54400758],\n",
       "       ...,\n",
       "       [0.54901909],\n",
       "       [0.54714307],\n",
       "       [0.53900049]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.layers[2]._grad_lf(nn.local_field_forwad(inputs,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
