{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.genfromtxt('data/training_set.csv', delimiter=',')\n",
    "validation_data = np.genfromtxt('data/validation_set.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    return data[:,0:2],np.expand_dims(data[:,-1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_inputs,training_outputs = preprocess_data(training_data)\n",
    "(training_inputs.shape,training_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs,validation_outputs = preprocess_data(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. define a layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer_Perceptron:\n",
    "    \n",
    "    def __init__(self,number_of_input,number_of_neurons,activation_function,derivate_activation_function,weight=None,bias=None,random_weight=True,weight_range=0.2,bias_range=1):\n",
    "        \n",
    "        self.n = number_of_input\n",
    "        self.m = number_of_neurons\n",
    "        self._activation_function = activation_function\n",
    "        self._derivate_activation_function = derivate_activation_function\n",
    "        \n",
    "        if (weight==None):\n",
    "            if random_weight:\n",
    "                self.w = weight_range*(2*np.random.rand(self.n,self.m)-1)\n",
    "            else:\n",
    "                self.w = np.zeros((self.n,self.m))\n",
    "        \n",
    "        else:\n",
    "            if not(weight.shape== (self.n,)):\n",
    "                raise ValueError(f\"weight param should be of shape ({self.n},) but it is {weight.shape}\")\n",
    "            else:\n",
    "                self.w = weight\n",
    "        \n",
    "        if (bias==None):\n",
    "            if random_weight:\n",
    "                self.b= bias_range*(2*np.random.rand(self.m,1)-1)\n",
    "            else:\n",
    "                self.b = 0\n",
    "        \n",
    "        else:\n",
    "            self.b = bias\n",
    "    \n",
    "    \n",
    "    def local_field(self,x):\n",
    "        return ((self.w.T@x.T) + self.b).T\n",
    "    \n",
    "    def activate(self,x):        \n",
    "        return self._activate_lf(self.local_field(x))\n",
    "    \n",
    "    def _activate_lf(self,lf):\n",
    "        return self._activation_function(lf)\n",
    "    \n",
    "    def grad(self,x):\n",
    "        return self._grad_lf(self.local_field(x))\n",
    "\n",
    "    def _grad_lf(self,lf):\n",
    "        return self._derivate_activation_function(lf)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = lambda x : np.tanh(x)\n",
    "derivate_activation_func = lambda x :  (1-np.tanh(x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = 3\n",
    "M2 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer_Perceptron(training_inputs.shape[1],M1,activation_func,derivate_activation_func)\n",
    "layer2 = Layer_Perceptron(layer1.w.shape[1],M2,activation_func,derivate_activation_func)\n",
    "layer3 = Layer_Perceptron(layer2.w.shape[1],1,activation_func,derivate_activation_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.activate(training_inputs[0:1,:]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Energies functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction:\n",
    "    \n",
    "    def __init__(self,loss,grad):\n",
    "        self.loss = loss\n",
    "        self.grad = grad\n",
    "    \n",
    "    def total_loss(self,inputs,outputs):\n",
    "        return self.loss(inputs,outputs).mean()\n",
    "    \n",
    "    def total_grad(self,inputs,outputs):\n",
    "        return self.grad(inputs,outputs).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_func(inputs,real_values):\n",
    "    return ((inputs-real_values)**2)\n",
    "\n",
    "def energy_derivate(inputs,real_values):\n",
    "    return 2*(inputs-real_values)\n",
    "\n",
    "energy = LossFunction(energy_func,energy_derivate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        \n",
    "        self.L = len(layers)\n",
    "        self.layers = layers\n",
    "    \n",
    "    def activate(self,inputs,l=None): \n",
    "        if l == None:\n",
    "            l= self.L-1\n",
    "        if l ==-1:\n",
    "            return inputs\n",
    "        return self.layers[l]._activate_lf(self.local_field_forwad(inputs,l))\n",
    "        \n",
    "        \n",
    "    def local_field_forwad(self,inputs,l):\n",
    "        outputs = inputs\n",
    "        for i in range(l):\n",
    "            outputs = self.layers[i].activate(outputs)\n",
    "        \n",
    " \n",
    "        local_field = self.layers[l].local_field(outputs)\n",
    "            \n",
    "        return local_field  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNet([layer1,layer2,layer3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.local_field_forwad(training_inputs,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.activate(training_inputs,2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = 5\n",
    "M2 = 7\n",
    "\n",
    "wr=10\n",
    "br=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer_Perceptron(training_inputs.shape[1],M1,activation_func,derivate_activation_func,weight_range=wr,bias_range=br)\n",
    "layer2 = Layer_Perceptron(layer1.w.shape[1],M2,activation_func,derivate_activation_func)\n",
    "layer3 = Layer_Perceptron(layer2.w.shape[1],1,activation_func,derivate_activation_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNet([layer1,layer2,layer3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = energy\n",
    "inputs = training_inputs\n",
    "outputs = training_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "max_iter = int(1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.zeros(max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 35.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f35374c5dc0>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grads_w = [np.zeros(layer.w.shape) for layer in nn.layers]\n",
    "grads_b = [np.zeros(layer.b.shape) for layer in nn.layers]\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(max_iter)):\n",
    "    \n",
    "    losses[epoch] = loss.total_loss(nn.activate(inputs),outputs)\n",
    "\n",
    "    \n",
    "    back_prop = loss.grad(nn.activate(inputs),outputs)\n",
    "    for i in reversed(range(nn.L)):\n",
    "        l = nn.layers[i]\n",
    "        nb_inputs = inputs.shape[0]\n",
    "\n",
    "        grad_layer = l._grad_lf(nn.local_field_forwad(inputs,i))\n",
    "        activation= nn.activate(inputs,i-1)\n",
    "\n",
    "\n",
    "        grads_w[i] = activation.T@(back_prop*grad_layer)/nb_inputs\n",
    "        grads_b[i] = (np.ones((activation.shape[0],1)).T@(back_prop*grad_layer)/nb_inputs).T\n",
    "\n",
    "        back_prop = (grad_layer*back_prop)@l.w.T/nb_inputs\n",
    "\n",
    "\n",
    "    for i in range(nn.L):\n",
    "\n",
    "        nn.layers[i].w =nn.layers[i].w - lr*grads_w[i]\n",
    "        nn.layers[i].b =nn.layers[i].b - lr*grads_b[i]\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
